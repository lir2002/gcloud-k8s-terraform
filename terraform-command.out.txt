Microsoft Windows [Version 10.0.19044.2486]

Ethan_Li@EPCNSZXW0050 C:\Users\Ethan_Li
$ d:

Ethan_Li@EPCNSZXW0050 D:\
$ cd dev

Ethan_Li@EPCNSZXW0050 D:\dev
$ git clone git clone https://github.com/hashicorp/learn-terraform-provision-gke-cluster gcloud-k8s-terraform
fatal: Too many arguments.

usage: git clone [<options>] [--] <repo> [<dir>]

    -v, --verbose         be more verbose
    -q, --quiet           be more quiet
    --progress            force progress reporting
    --reject-shallow      don't clone shallow repository
    -n, --no-checkout     don't create a checkout
    --bare                create a bare repository
    --mirror              create a mirror repository (implies bare)
    -l, --local           to clone from a local repository
    --no-hardlinks        don't use local hardlinks, always copy
    -s, --shared          setup as shared repository
    --recurse-submodules[=<pathspec>]
                          initialize submodules in the clone
    --recursive ...       alias of --recurse-submodules
    -j, --jobs <n>        number of submodules cloned in parallel
    --template <template-directory>
                          directory from which templates will be used
    --reference <repo>    reference repository
    --reference-if-able <repo>
                          reference repository
    --dissociate          use --reference only while cloning
    -o, --origin <name>   use <name> instead of 'origin' to track upstream
    -b, --branch <branch>
                          checkout <branch> instead of the remote's HEAD
    -u, --upload-pack <path>
                          path to git-upload-pack on the remote
    --depth <depth>       create a shallow clone of that depth
    --shallow-since <time>
                          create a shallow clone since a specific time
    --shallow-exclude <revision>
                          deepen history of shallow clone, excluding rev
    --single-branch       clone only one branch, HEAD or --branch
    --no-tags             don't clone any tags, and make later fetches not to follow them
    --shallow-submodules  any cloned submodules will be shallow
    --separate-git-dir <gitdir>
                          separate git dir from working tree
    -c, --config <key=value>
                          set config inside the new repository
    --server-option <server-specific>
                          option to transmit
    -4, --ipv4            use IPv4 addresses only
    -6, --ipv6            use IPv6 addresses only
    --filter <args>       object filtering
    --remote-submodules   any cloned submodules will use their remote-tracking branch
    --sparse              initialize sparse-checkout file to include only files at root


Ethan_Li@EPCNSZXW0050 D:\dev
$  git clone https://github.com/hashicorp/learn-terraform-provision-gke-cluster gcloud-k8s-terraform
Cloning into 'gcloud-k8s-terraform'...
remote: Enumerating objects: 100, done.
remote: Counting objects: 100% (56/56), done.
remote: Compressing objects: 100% (31/31), done.
remote: Total 100 (delta 38), reused 28 (delta 25), pack-reused 44
Receiving objects: 100% (100/100), 28.12 KiB | 411.00 KiB/s, done.
Resolving deltas: 100% (49/49), done.

Ethan_Li@EPCNSZXW0050 D:\dev
$ cd gcloud-k8s-terraform

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform init

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/google from the dependency lock file
- Installing hashicorp/google v4.27.0...
- Installed hashicorp/google v4.27.0 (signed by HashiCorp)

Terraform has made some changes to the provider dependency selections recorded
in the .terraform.lock.hcl file. Review those changes and commit them to your
version control system if they represent changes you intended to make.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.C.tfplan
╷
│ Error: Attempted to load application default credentials since neither `credentials` nor `access_token` was set in the provider block.  No credentials loaded. To use your gcloud credentials, run 'gcloud auth application-default login'.  Original error: google: could not find default credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.
│
│   with provider["registry.terraform.io/hashicorp/google"],
│   on vpc.tf line 9, in provider "google":
│    9: provider "google" {
│
╵

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud auth application-default login
Your browser has been opened to visit:

    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=8TR6kelxbvUYZIbcI3Tqk9NQYdXLEU&access_type=offline&code_challenge=-xKwKNaSfWyd1Df71OWBhFmV5sm837wZrHeuPLX1zrI&code_challenge_method=S256


Credentials saved to file: [C:\Users\Ethan_Li\AppData\Roaming\gcloud\application_default_credentials.json]

These credentials will be used by any library that requests Application Default Credentials (ADC).

Quota project "valentine-night" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.C.tfplan
╷
│ Error: "name" ("Deadpool-subnet") doesn't match regexp "^(?:[a-z](?:[-a-z0-9]{0,61}[a-z0-9])?)$"
│
│   with google_compute_subnetwork.subnet,
│   on vpc.tf line 22, in resource "google_compute_subnetwork" "subnet":
│   22:   name          = "${var.project_id}-subnet"
│
╵

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.C.tfplan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_network.vpc will be created
  + resource "google_compute_network" "vpc" {
      + auto_create_subnetworks         = false
      + delete_default_routes_on_create = false
      + gateway_ipv4                    = (known after apply)
      + id                              = (known after apply)
      + internal_ipv6_range             = (known after apply)
      + mtu                             = (known after apply)
      + name                            = "deadpool-vpc"
      + project                         = (known after apply)
      + routing_mode                    = (known after apply)
      + self_link                       = (known after apply)
    }

  # google_compute_subnetwork.subnet will be created
  + resource "google_compute_subnetwork" "subnet" {
      + creation_timestamp         = (known after apply)
      + external_ipv6_prefix       = (known after apply)
      + fingerprint                = (known after apply)
      + gateway_address            = (known after apply)
      + id                         = (known after apply)
      + ip_cidr_range              = "10.10.0.0/24"
      + ipv6_cidr_range            = (known after apply)
      + name                       = "deadpool-subnet"
      + network                    = "deadpool-vpc"
      + private_ipv6_google_access = (known after apply)
      + project                    = (known after apply)
      + purpose                    = (known after apply)
      + region                     = "asia-south1"
      + secondary_ip_range         = (known after apply)
      + self_link                  = (known after apply)
      + stack_type                 = (known after apply)
    }

  # google_container_cluster.primary will be created
  + resource "google_container_cluster" "primary" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_legacy_abac          = false
      + enable_shielded_nodes       = true
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 1
      + label_fingerprint           = (known after apply)
      + location                    = "asia-south1"
      + logging_service             = (known after apply)
      + master_version              = (known after apply)
      + monitoring_service          = (known after apply)
      + name                        = "deadpool-gke"
      + network                     = "deadpool-vpc"
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + remove_default_node_pool    = true
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = "deadpool-subnet"
      + tpu_ipv4_cidr_block         = (known after apply)

      + addons_config {
          + cloudrun_config {
              + disabled           = (known after apply)
              + load_balancer_type = (known after apply)
            }

          + gcp_filestore_csi_driver_config {
              + enabled = (known after apply)
            }

          + horizontal_pod_autoscaling {
              + disabled = (known after apply)
            }

          + http_load_balancing {
              + disabled = (known after apply)
            }

          + network_policy_config {
              + disabled = (known after apply)
            }
        }

      + authenticator_groups_config {
          + security_group = (known after apply)
        }

      + cluster_autoscaling {
          + enabled = (known after apply)

          + auto_provisioning_defaults {
              + image_type      = (known after apply)
              + oauth_scopes    = (known after apply)
              + service_account = (known after apply)
            }

          + resource_limits {
              + maximum       = (known after apply)
              + minimum       = (known after apply)
              + resource_type = (known after apply)
            }
        }

      + confidential_nodes {
          + enabled = (known after apply)
        }

      + database_encryption {
          + key_name = (known after apply)
          + state    = (known after apply)
        }

      + default_snat_status {
          + disabled = (known after apply)
        }

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = (known after apply)
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = (known after apply)
          + services_secondary_range_name = (known after apply)
        }

      + logging_config {
          + enable_components = (known after apply)
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = (known after apply)
            }
        }

      + monitoring_config {
          + enable_components = (known after apply)
        }

      + node_config {
          + boot_disk_kms_key = (known after apply)
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + machine_type      = (known after apply)
          + metadata          = (known after apply)
          + min_cpu_platform  = (known after apply)
          + node_group        = (known after apply)
          + oauth_scopes      = (known after apply)
          + preemptible       = (known after apply)
          + service_account   = (known after apply)
          + spot              = (known after apply)
          + tags              = (known after apply)
          + taint             = (known after apply)

          + gcfs_config {
              + enabled = (known after apply)
            }

          + gvnic {
              + enabled = (known after apply)
            }

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + node_pool {
          + initial_node_count          = (known after apply)
          + instance_group_urls         = (known after apply)
          + managed_instance_group_urls = (known after apply)
          + max_pods_per_node           = (known after apply)
          + name                        = (known after apply)
          + name_prefix                 = (known after apply)
          + node_count                  = (known after apply)
          + node_locations              = (known after apply)
          + version                     = (known after apply)

          + autoscaling {
              + max_node_count = (known after apply)
              + min_node_count = (known after apply)
            }

          + management {
              + auto_repair  = (known after apply)
              + auto_upgrade = (known after apply)
            }

          + node_config {
              + boot_disk_kms_key = (known after apply)
              + disk_size_gb      = (known after apply)
              + disk_type         = (known after apply)
              + guest_accelerator = (known after apply)
              + image_type        = (known after apply)
              + labels            = (known after apply)
              + local_ssd_count   = (known after apply)
              + machine_type      = (known after apply)
              + metadata          = (known after apply)
              + min_cpu_platform  = (known after apply)
              + node_group        = (known after apply)
              + oauth_scopes      = (known after apply)
              + preemptible       = (known after apply)
              + service_account   = (known after apply)
              + spot              = (known after apply)
              + tags              = (known after apply)
              + taint             = (known after apply)

              + gcfs_config {
                  + enabled = (known after apply)
                }

              + gvnic {
                  + enabled = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + workload_metadata_config {
                  + mode = (known after apply)
                }
            }

          + upgrade_settings {
              + max_surge       = (known after apply)
              + max_unavailable = (known after apply)
            }
        }

      + release_channel {
          + channel = (known after apply)
        }

      + vertical_pod_autoscaling {
          + enabled = (known after apply)
        }

      + workload_identity_config {
          + workload_pool = (known after apply)
        }
    }

  # google_container_node_pool.primary_nodes will be created
  + resource "google_container_node_pool" "primary_nodes" {
      + cluster                     = "deadpool-gke"
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "asia-south1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = "deadpool-gke"
      + name_prefix                 = (known after apply)
      + node_count                  = 2
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = (known after apply)

      + management {
          + auto_repair  = (known after apply)
          + auto_upgrade = (known after apply)
        }

      + node_config {
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = {
              + "env" = "deadpool"
            }
          + local_ssd_count   = (known after apply)
          + machine_type      = "n1-standard-1"
          + metadata          = {
              + "disable-legacy-endpoints" = "true"
            }
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + tags              = [
              + "gke-node",
              + "deadpool-gke",
            ]
          + taint             = (known after apply)

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + upgrade_settings {
          + max_surge       = (known after apply)
          + max_unavailable = (known after apply)
        }
    }

Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + kubernetes_cluster_host = (known after apply)
  + kubernetes_cluster_name = "deadpool-gke"
  + project_id              = "deadpool"
  + region                  = "asia-south1"

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: PLAN.C.tfplan

To perform exactly these actions, run the following command to apply:
    terraform apply "PLAN.C.tfplan"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
 $  terraform apply "PLAN.C.tfplan"
 google_compute_network.vpc: Creating...
 ╷
 │ Error: Error creating Network: googleapi: Error 403: Compute Engine API has not been used in project 466609933162 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/compute.googleapis.com/overview?project=466609933162 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.
 │ Details:
 │ [
 │   {
 │     "@type": "type.googleapis.com/google.rpc.Help",
 │     "links": [
 │       {
 │         "description": "Google developers console API activation",
 │         "url": "https://console.developers.google.com/apis/api/compute.googleapis.com/overview?project=466609933162"
 │       }
 │     ]
 │   },
 │   {
 │     "@type": "type.googleapis.com/google.rpc.ErrorInfo",
 │     "domain": "googleapis.com",
 │     "metadatas": {
 │       "consumer": "projects/466609933162",
 │       "service": "compute.googleapis.com"
 │     },
 │     "reason": "SERVICE_DISABLED"
 │   }
 │ ]
 │ , accessNotConfigured
 │
 │   with google_compute_network.vpc,
 │   on vpc.tf line 15, in resource "google_compute_network" "vpc":
 │   15: resource "google_compute_network" "vpc" {
 │
 ╵
 Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
 $ terraform apply "PLAN.R.tfplan"
 google_compute_network.vpc: Creating...
 google_compute_network.vpc: Still creating... [10s elapsed]
 google_compute_network.vpc: Creation complete after 12s [id=projects/valentine-night/global/networks/valentine-night-vpc]
 google_compute_subnetwork.subnet: Creating...
 google_compute_subnetwork.subnet: Still creating... [10s elapsed]
 google_compute_subnetwork.subnet: Still creating... [20s elapsed]
 google_compute_subnetwork.subnet: Creation complete after 29s [id=projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet]
 google_container_cluster.primary: Creating...
 ╷
 │ Error: googleapi: Error 400: Failed precondition when calling the ServiceConsumerManager: tenantmanager::185014: Consumer 242643787068 should enable service:container.googleapis.com before generating a service account.
 │ com.google.api.tenant.error.TenantManagerException: Consumer 242643787068 should enable service:container.googleapis.com before generating a service account., failedPrecondition
 │
 │   with google_container_cluster.primary,
 │   on gke.tf line 17, in resource "google_container_cluster" "primary":
 │   17: resource "google_container_cluster" "primary" {
 │
 ╵

 Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
 $ terraform show
 # google_compute_network.vpc:
 resource "google_compute_network" "vpc" {
     auto_create_subnetworks         = false
     delete_default_routes_on_create = false
     enable_ula_internal_ipv6        = false
     id                              = "projects/valentine-night/global/networks/valentine-night-vpc"
     mtu                             = 0
     name                            = "valentine-night-vpc"
     project                         = "valentine-night"
     routing_mode                    = "REGIONAL"
     self_link                       = "https://www.googleapis.com/compute/v1/projects/valentine-night/global/networks/valentine-night-vpc"
 }

 # google_compute_subnetwork.subnet:
 resource "google_compute_subnetwork" "subnet" {
     creation_timestamp         = "2023-02-13T01:29:02.734-08:00"
     gateway_address            = "10.10.0.1"
     id                         = "projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet"
     ip_cidr_range              = "10.10.0.0/24"
     name                       = "valentine-night-subnet"
     network                    = "https://www.googleapis.com/compute/v1/projects/valentine-night/global/networks/valentine-night-vpc"
     private_ip_google_access   = false
     private_ipv6_google_access = "DISABLE_GOOGLE_ACCESS"
     project                    = "valentine-night"
     purpose                    = "PRIVATE"
     region                     = "asia-south1"
     secondary_ip_range         = []
     self_link                  = "https://www.googleapis.com/compute/v1/projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet"
     stack_type                 = "IPV4_ONLY"
 }


 Outputs:

 kubernetes_cluster_name = "valentine-night-gke"
 project_id = "valentine-night"
 region = "asia-south1"
Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud services enable container.googleapis.com
Operation "operations/acf.p2-242643787068-7dbea3d1-1ba3-4372-86c9-c58eb1ce2a95" finished successfully.

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.R.2.tfplan
google_compute_network.vpc: Refreshing state... [id=projects/valentine-night/global/networks/valentine-night-vpc]
google_compute_subnetwork.subnet: Refreshing state... [id=projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_container_cluster.primary will be created
  + resource "google_container_cluster" "primary" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_legacy_abac          = false
      + enable_shielded_nodes       = true
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 1
      + label_fingerprint           = (known after apply)
      + location                    = "asia-south1"
      + logging_service             = (known after apply)
      + master_version              = (known after apply)
      + monitoring_service          = (known after apply)
      + name                        = "valentine-night-gke"
      + network                     = "valentine-night-vpc"
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + remove_default_node_pool    = true
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = "valentine-night-subnet"
      + tpu_ipv4_cidr_block         = (known after apply)

      + addons_config {
          + cloudrun_config {
              + disabled           = (known after apply)
              + load_balancer_type = (known after apply)
            }

          + gcp_filestore_csi_driver_config {
              + enabled = (known after apply)
            }

          + horizontal_pod_autoscaling {
              + disabled = (known after apply)
            }

          + http_load_balancing {
              + disabled = (known after apply)
            }

          + network_policy_config {
              + disabled = (known after apply)
            }
        }

      + authenticator_groups_config {
          + security_group = (known after apply)
        }

      + cluster_autoscaling {
          + enabled = (known after apply)

          + auto_provisioning_defaults {
              + image_type      = (known after apply)
              + oauth_scopes    = (known after apply)
              + service_account = (known after apply)
            }

          + resource_limits {
              + maximum       = (known after apply)
              + minimum       = (known after apply)
              + resource_type = (known after apply)
            }
        }

      + confidential_nodes {
          + enabled = (known after apply)
        }

      + database_encryption {
          + key_name = (known after apply)
          + state    = (known after apply)
        }

      + default_snat_status {
          + disabled = (known after apply)
        }

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = (known after apply)
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = (known after apply)
          + services_secondary_range_name = (known after apply)
        }

      + logging_config {
          + enable_components = (known after apply)
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = (known after apply)
            }
        }

      + monitoring_config {
          + enable_components = (known after apply)
        }

      + node_config {
          + boot_disk_kms_key = (known after apply)
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + machine_type      = (known after apply)
          + metadata          = (known after apply)
          + min_cpu_platform  = (known after apply)
          + node_group        = (known after apply)
          + oauth_scopes      = (known after apply)
          + preemptible       = (known after apply)
          + service_account   = (known after apply)
          + spot              = (known after apply)
          + tags              = (known after apply)
          + taint             = (known after apply)

          + gcfs_config {
              + enabled = (known after apply)
            }

          + gvnic {
              + enabled = (known after apply)
            }

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + node_pool {
          + initial_node_count          = (known after apply)
          + instance_group_urls         = (known after apply)
          + managed_instance_group_urls = (known after apply)
          + max_pods_per_node           = (known after apply)
          + name                        = (known after apply)
          + name_prefix                 = (known after apply)
          + node_count                  = (known after apply)
          + node_locations              = (known after apply)
          + version                     = (known after apply)

          + autoscaling {
              + max_node_count = (known after apply)
              + min_node_count = (known after apply)
            }

          + management {
              + auto_repair  = (known after apply)
              + auto_upgrade = (known after apply)
            }

          + node_config {
              + boot_disk_kms_key = (known after apply)
              + disk_size_gb      = (known after apply)
              + disk_type         = (known after apply)
              + guest_accelerator = (known after apply)
              + image_type        = (known after apply)
              + labels            = (known after apply)
              + local_ssd_count   = (known after apply)
              + machine_type      = (known after apply)
              + metadata          = (known after apply)
              + min_cpu_platform  = (known after apply)
              + node_group        = (known after apply)
              + oauth_scopes      = (known after apply)
              + preemptible       = (known after apply)
              + service_account   = (known after apply)
              + spot              = (known after apply)
              + tags              = (known after apply)
              + taint             = (known after apply)

              + gcfs_config {
                  + enabled = (known after apply)
                }

              + gvnic {
                  + enabled = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + workload_metadata_config {
                  + mode = (known after apply)
                }
            }

          + upgrade_settings {
              + max_surge       = (known after apply)
              + max_unavailable = (known after apply)
            }
        }

      + release_channel {
          + channel = (known after apply)
        }

      + vertical_pod_autoscaling {
          + enabled = (known after apply)
        }

      + workload_identity_config {
          + workload_pool = (known after apply)
        }
    }

  # google_container_node_pool.primary_nodes will be created
  + resource "google_container_node_pool" "primary_nodes" {
      + cluster                     = "valentine-night-gke"
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "asia-south1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = "valentine-night-gke"
      + name_prefix                 = (known after apply)
      + node_count                  = 2
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = (known after apply)

      + management {
          + auto_repair  = (known after apply)
          + auto_upgrade = (known after apply)
        }

      + node_config {
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = {
              + "env" = "valentine-night"
            }
          + local_ssd_count   = (known after apply)
          + machine_type      = "n1-standard-1"
          + metadata          = {
              + "disable-legacy-endpoints" = "true"
            }
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + tags              = [
              + "gke-node",
              + "valentine-night-gke",
            ]
          + taint             = (known after apply)

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + upgrade_settings {
          + max_surge       = (known after apply)
          + max_unavailable = (known after apply)
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + kubernetes_cluster_host = (known after apply)

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: PLAN.R.2.tfplan

To perform exactly these actions, run the following command to apply:
    terraform apply "PLAN.R.2.tfplan"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$  terraform apply "PLAN.R.2.tfplan
google_container_cluster.primary: Creating...
google_container_cluster.primary: Still creating... [10s elapsed]
google_container_cluster.primary: Still creating... [20s elapsed]
google_container_cluster.primary: Still creating... [30s elapsed]
google_container_cluster.primary: Still creating... [40s elapsed]
google_container_cluster.primary: Still creating... [50s elapsed]
google_container_cluster.primary: Still creating... [1m0s elapsed]
google_container_cluster.primary: Still creating... [1m10s elapsed]
google_container_cluster.primary: Still creating... [1m21s elapsed]
google_container_cluster.primary: Still creating... [1m31s elapsed]
google_container_cluster.primary: Still creating... [1m41s elapsed]
google_container_cluster.primary: Still creating... [1m51s elapsed]
google_container_cluster.primary: Still creating... [2m1s elapsed]
google_container_cluster.primary: Still creating... [2m11s elapsed]
google_container_cluster.primary: Still creating... [2m21s elapsed]
google_container_cluster.primary: Still creating... [2m31s elapsed]
google_container_cluster.primary: Still creating... [2m41s elapsed]
google_container_cluster.primary: Still creating... [2m51s elapsed]
google_container_cluster.primary: Still creating... [3m1s elapsed]
google_container_cluster.primary: Still creating... [3m11s elapsed]
google_container_cluster.primary: Still creating... [3m21s elapsed]
google_container_cluster.primary: Still creating... [3m31s elapsed]
google_container_cluster.primary: Still creating... [3m41s elapsed]
google_container_cluster.primary: Still creating... [3m51s elapsed]
google_container_cluster.primary: Still creating... [4m1s elapsed]
google_container_cluster.primary: Still creating... [4m11s elapsed]
google_container_cluster.primary: Still creating... [4m21s elapsed]
google_container_cluster.primary: Still creating... [4m31s elapsed]
google_container_cluster.primary: Still creating... [4m41s elapsed]
google_container_cluster.primary: Still creating... [4m51s elapsed]
google_container_cluster.primary: Still creating... [5m1s elapsed]
google_container_cluster.primary: Still creating... [5m11s elapsed]
google_container_cluster.primary: Creation complete after 5m15s [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke]
google_container_node_pool.primary_nodes: Creating...
╷
│ Error: error creating NodePool: googleapi: Error 403: Insufficient regional quota to satisfy request: resource "SSD_TOTAL_GB": request requires '600.0' and is short '110.0'. project has a quota of '500.0' with '490.0' available. View and manage quotas at https://console.cloud.google.com/iam-admin/quotas?usage=USED&project=valentine-night., forbidden
│
│   with google_container_node_pool.primary_nodes,
│   on gke.tf line 32, in resource "google_container_node_pool" "primary_nodes":
│   32: resource "google_container_node_pool" "primary_nodes" {
│
╵

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform show
# google_compute_network.vpc:
resource "google_compute_network" "vpc" {
    auto_create_subnetworks         = false
    delete_default_routes_on_create = false
    enable_ula_internal_ipv6        = false
    id                              = "projects/valentine-night/global/networks/valentine-night-vpc"
    mtu                             = 0
    name                            = "valentine-night-vpc"
    project                         = "valentine-night"
    routing_mode                    = "REGIONAL"
    self_link                       = "https://www.googleapis.com/compute/v1/projects/valentine-night/global/networks/valentine-night-vpc"
}

# google_compute_subnetwork.subnet:
resource "google_compute_subnetwork" "subnet" {
    creation_timestamp         = "2023-02-13T01:29:02.734-08:00"
    gateway_address            = "10.10.0.1"
    id                         = "projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet"
    ip_cidr_range              = "10.10.0.0/24"
    name                       = "valentine-night-subnet"
    network                    = "https://www.googleapis.com/compute/v1/projects/valentine-night/global/networks/valentine-night-vpc"
    private_ip_google_access   = false
    private_ipv6_google_access = "DISABLE_GOOGLE_ACCESS"
    project                    = "valentine-night"
    purpose                    = "PRIVATE"
    region                     = "asia-south1"
    secondary_ip_range         = []
    self_link                  = "https://www.googleapis.com/compute/v1/projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet"
    stack_type                 = "IPV4_ONLY"
}

# google_container_cluster.primary:
resource "google_container_cluster" "primary" {
    cluster_ipv4_cidr           = "10.180.0.0/14"
    enable_autopilot            = false
    enable_binary_authorization = false
    enable_intranode_visibility = false
    enable_kubernetes_alpha     = false
    enable_legacy_abac          = false
    enable_shielded_nodes       = true
    enable_tpu                  = false
    endpoint                    = "34.93.54.93"
    id                          = "projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke"
    initial_node_count          = 1
    label_fingerprint           = "a9dc16a7"
    location                    = "asia-south1"
    logging_service             = "logging.googleapis.com/kubernetes"
    master_version              = "1.24.8-gke.2000"
    monitoring_service          = "monitoring.googleapis.com/kubernetes"
    name                        = "valentine-night-gke"
    network                     = "projects/valentine-night/global/networks/valentine-night-vpc"
    networking_mode             = "ROUTES"
    node_locations              = [
        "asia-south1-a",
        "asia-south1-b",
        "asia-south1-c",
    ]
    node_version                = "1.24.8-gke.2000"
    project                     = "valentine-night"
    remove_default_node_pool    = true
    self_link                   = "https://container.googleapis.com/v1/projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke"
    services_ipv4_cidr          = "10.183.240.0/20"
    subnetwork                  = "projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet"

    addons_config {

        network_policy_config {
            disabled = true
        }
    }

    cluster_autoscaling {
        enabled = false
    }

    database_encryption {
        state = "DECRYPTED"
    }

    default_snat_status {
        disabled = false
    }

    logging_config {
        enable_components = [
            "SYSTEM_COMPONENTS",
            "WORKLOADS",
        ]
    }

    master_auth {
        cluster_ca_certificate = "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"

        client_certificate_config {
            issue_client_certificate = false
        }
    }

    monitoring_config {
        enable_components = [
            "SYSTEM_COMPONENTS",
        ]
    }

    network_policy {
        enabled  = false
        provider = "PROVIDER_UNSPECIFIED"
    }

    private_cluster_config {
        enable_private_endpoint = false
        enable_private_nodes    = false
        private_endpoint        = "10.10.0.2"
        public_endpoint         = "34.93.54.93"

        master_global_access_config {
            enabled = false
        }
    }

    release_channel {
        channel = "REGULAR"
    }
}

# google_container_node_pool.primary_nodes: (tainted)
resource "google_container_node_pool" "primary_nodes" {
    cluster        = "valentine-night-gke"
    id             = "projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke/nodePools/valentine-night-gke"
    location       = "asia-south1"
    name           = "valentine-night-gke"
    node_count     = 2
    node_locations = []

    node_config {
        disk_size_gb      = 0
        guest_accelerator = []
        labels            = {
            "env" = "valentine-night"
        }
        local_ssd_count   = 0
        machine_type      = "n1-standard-1"
        metadata          = {
            "disable-legacy-endpoints" = "true"
        }
        oauth_scopes      = [
            "https://www.googleapis.com/auth/logging.write",
            "https://www.googleapis.com/auth/monitoring",
        ]
        preemptible       = false
        spot              = false
        tags              = [
            "gke-node",
            "valentine-night-gke",
        ]
        taint             = []
    }
}


Outputs:

kubernetes_cluster_host = "34.93.54.93"
kubernetes_cluster_name = "valentine-night-gke"
project_id = "valentine-night"
region = "asia-south1"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.Destroy.tfplan -destroy
google_compute_network.vpc: Refreshing state... [id=projects/valentine-night/global/networks/valentine-night-vpc]
google_compute_subnetwork.subnet: Refreshing state... [id=projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet]
google_container_cluster.primary: Refreshing state... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke]
google_container_node_pool.primary_nodes: Refreshing state... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke/nodePools/valentine-night-gke]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # google_compute_network.vpc will be destroyed
  - resource "google_compute_network" "vpc" {
      - auto_create_subnetworks         = false -> null
      - delete_default_routes_on_create = false -> null
      - enable_ula_internal_ipv6        = false -> null
      - id                              = "projects/valentine-night/global/networks/valentine-night-vpc" -> null
      - mtu                             = 0 -> null
      - name                            = "valentine-night-vpc" -> null
      - project                         = "valentine-night" -> null
      - routing_mode                    = "REGIONAL" -> null
      - self_link                       = "https://www.googleapis.com/compute/v1/projects/valentine-night/global/networks/valentine-night-vpc" -> null
    }

  # google_compute_subnetwork.subnet will be destroyed
  - resource "google_compute_subnetwork" "subnet" {
      - creation_timestamp         = "2023-02-13T01:29:02.734-08:00" -> null
      - gateway_address            = "10.10.0.1" -> null
      - id                         = "projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet" -> null
      - ip_cidr_range              = "10.10.0.0/24" -> null
      - name                       = "valentine-night-subnet" -> null
      - network                    = "https://www.googleapis.com/compute/v1/projects/valentine-night/global/networks/valentine-night-vpc" -> null
      - private_ip_google_access   = true -> null
      - private_ipv6_google_access = "DISABLE_GOOGLE_ACCESS" -> null
      - project                    = "valentine-night" -> null
      - purpose                    = "PRIVATE" -> null
      - region                     = "asia-south1" -> null
      - secondary_ip_range         = [] -> null
      - self_link                  = "https://www.googleapis.com/compute/v1/projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet" -> null
      - stack_type                 = "IPV4_ONLY" -> null
    }

  # google_container_cluster.primary will be destroyed
  - resource "google_container_cluster" "primary" {
      - cluster_ipv4_cidr           = "10.180.0.0/14" -> null
      - enable_autopilot            = false -> null
      - enable_binary_authorization = false -> null
      - enable_intranode_visibility = false -> null
      - enable_kubernetes_alpha     = false -> null
      - enable_legacy_abac          = false -> null
      - enable_shielded_nodes       = true -> null
      - enable_tpu                  = false -> null
      - endpoint                    = "34.93.54.93" -> null
      - id                          = "projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke" -> null
      - initial_node_count          = 1 -> null
      - label_fingerprint           = "a9dc16a7" -> null
      - location                    = "asia-south1" -> null
      - logging_service             = "logging.googleapis.com/kubernetes" -> null
      - master_version              = "1.24.8-gke.2000" -> null
      - monitoring_service          = "monitoring.googleapis.com/kubernetes" -> null
      - name                        = "valentine-night-gke" -> null
      - network                     = "projects/valentine-night/global/networks/valentine-night-vpc" -> null
      - networking_mode             = "ROUTES" -> null
      - node_locations              = [
          - "asia-south1-a",
          - "asia-south1-b",
          - "asia-south1-c",
        ] -> null
      - node_version                = "1.24.8-gke.2000" -> null
      - project                     = "valentine-night" -> null
      - remove_default_node_pool    = true -> null
      - resource_labels             = {} -> null
      - self_link                   = "https://container.googleapis.com/v1/projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke" -> null
      - services_ipv4_cidr          = "10.183.240.0/20" -> null
      - subnetwork                  = "projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet" -> null

      - addons_config {

          - network_policy_config {
              - disabled = true -> null
            }
        }

      - cluster_autoscaling {
          - enabled = false -> null
        }

      - database_encryption {
          - state = "DECRYPTED" -> null
        }

      - default_snat_status {
          - disabled = false -> null
        }

      - logging_config {
          - enable_components = [
              - "SYSTEM_COMPONENTS",
              - "WORKLOADS",
            ] -> null
        }

      - master_auth {
          - cluster_ca_certificate = "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" -> null

          - client_certificate_config {
              - issue_client_certificate = false -> null
            }
        }

      - monitoring_config {
          - enable_components = [
              - "SYSTEM_COMPONENTS",
            ] -> null
        }

      - network_policy {
          - enabled  = false -> null
          - provider = "PROVIDER_UNSPECIFIED" -> null
        }

      - private_cluster_config {
          - enable_private_endpoint = false -> null
          - enable_private_nodes    = false -> null
          - private_endpoint        = "10.10.0.2" -> null
          - public_endpoint         = "34.93.54.93" -> null

          - master_global_access_config {
              - enabled = false -> null
            }
        }

      - release_channel {
          - channel = "REGULAR" -> null
        }
    }

Plan: 0 to add, 0 to change, 3 to destroy.

Changes to Outputs:
  - kubernetes_cluster_host = "34.93.54.93" -> null
  - kubernetes_cluster_name = "valentine-night-gke" -> null
  - project_id              = "valentine-night" -> null
  - region                  = "asia-south1" -> null

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: PLAN.Destroy.tfplan

To perform exactly these actions, run the following command to apply:
    terraform apply "PLAN.Destroy.tfplan"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform apply "PLAN.Destroy.tfplan"
google_container_cluster.primary: Destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 1m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 1m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 1m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 1m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 1m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 1m50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 2m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 2m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 2m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 2m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 2m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 2m50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 3m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 3m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 3m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 3m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 3m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 3m50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 4m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 4m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 4m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 4m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 4m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 4m50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 5m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 5m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 5m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 5m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 5m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/valentine-night/locations/asia-south1/clusters/valentine-night-gke, 5m50s elapsed]
google_container_cluster.primary: Destruction complete after 5m56s
google_compute_subnetwork.subnet: Destroying... [id=projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet]
google_compute_subnetwork.subnet: Still destroying... [id=projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet, 10s elapsed]
google_compute_subnetwork.subnet: Still destroying... [id=projects/valentine-night/regions/asia-south1/subnetworks/valentine-night-subnet, 20s elapsed]
google_compute_subnetwork.subnet: Destruction complete after 25s
google_compute_network.vpc: Destroying... [id=projects/valentine-night/global/networks/valentine-night-vpc]
google_compute_network.vpc: Still destroying... [id=projects/valentine-night/global/networks/valentine-night-vpc, 10s elapsed]
google_compute_network.vpc: Still destroying... [id=projects/valentine-night/global/networks/valentine-night-vpc, 20s elapsed]
google_compute_network.vpc: Destruction complete after 22s

Apply complete! Resources: 0 added, 0 changed, 3 destroyed.

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$


Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform destroy
google_compute_network.vpc: Refreshing state... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_subnetwork.subnet: Refreshing state... [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # google_compute_network.vpc will be destroyed
  - resource "google_compute_network" "vpc" {
      - auto_create_subnetworks         = false -> null
      - delete_default_routes_on_create = false -> null
      - enable_ula_internal_ipv6        = false -> null
      - id                              = "projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
      - mtu                             = 0 -> null
      - name                            = "gks-nowhere-vpc" -> null
      - project                         = "gks-nowhere" -> null
      - routing_mode                    = "REGIONAL" -> null
      - self_link                       = "https://www.googleapis.com/compute/v1/projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
    }

  # google_compute_subnetwork.subnet will be destroyed
  - resource "google_compute_subnetwork" "subnet" {
      - creation_timestamp         = "2023-02-13T06:05:53.957-08:00" -> null
      - gateway_address            = "10.10.0.1" -> null
      - id                         = "projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet" -> null
      - ip_cidr_range              = "10.10.0.0/24" -> null
      - name                       = "gks-nowhere-subnet" -> null
      - network                    = "https://www.googleapis.com/compute/v1/projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
      - private_ip_google_access   = false -> null
      - private_ipv6_google_access = "DISABLE_GOOGLE_ACCESS" -> null
      - project                    = "gks-nowhere" -> null
      - purpose                    = "PRIVATE" -> null
      - region                     = "us-east1" -> null
      - secondary_ip_range         = [] -> null
      - self_link                  = "https://www.googleapis.com/compute/v1/projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet" -> null
      - stack_type                 = "IPV4_ONLY" -> null
    }

Plan: 0 to add, 0 to change, 2 to destroy.

Changes to Outputs:
  - kubernetes_cluster_name = "gks-nowhere-gke" -> null
  - project_id              = "gks-nowhere" -> null
  - region                  = "us-east1" -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

google_compute_subnetwork.subnet: Destroying... [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]
google_compute_subnetwork.subnet: Still destroying... [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet, 10s elapsed]
google_compute_subnetwork.subnet: Destruction complete after 13s
google_compute_network.vpc: Destroying... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_network.vpc: Still destroying... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc, 10s elapsed]
google_compute_network.vpc: Still destroying... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc, 20s elapsed]
google_compute_network.vpc: Destruction complete after 22s

Destroy complete! Resources: 2 destroyed.

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config set
ERROR: (gcloud.config.set) argument SECTION/PROPERTY VALUE: Must be specified.
Usage: gcloud config set SECTION/PROPERTY VALUE [optional flags]
  optional flags may be  --help | --installation

For detailed information on this command and its flags, run:
  gcloud config set --help

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config list
[accessibility]
screen_reader = False
[compute]
region = asia-south1
zone = asia-south1-c
[core]
account = lir2002@gmail.com
disable_usage_reporting = True
project = valentine-night

Your active configuration is: [default]

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config set project who
WARNING: You do not appear to have access to project [who] or it does not exist.
Are you sure you wish to set property [core/project] to who?

Do you want to continue (Y/n)?  n


Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config set project gks-nowhere
Updated property [core/project].

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config set compute/region us-east1
Updated property [compute/region].

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config list
[accessibility]
screen_reader = False
[compute]
region = us-east1
zone = asia-south1-c
[core]
account = lir2002@gmail.com
disable_usage_reporting = True
project = gks-nowhere

Your active configuration is: [default]

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config set compute/zone us-east1-c
Updated property [compute/zone].

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config set compute/zone us-east1-ccc
WARNING: us-east1-ccc is not a valid zone. Run `gcloud compute zones list` to get all zones.
Are you sure you wish to set property [compute/zone] to us-east1-ccc?

Do you want to continue (Y/n)?  n


Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud config list
[accessibility]
screen_reader = False
[compute]
region = us-east1
zone = us-east1-c
[core]
account = lir2002@gmail.com
disable_usage_reporting = True
project = gks-nowhere

Your active configuration is: [default]

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ gcloud services enable container.googleapis.com
Operation "operations/acf.p2-448648557068-9ca96bda-7a20-4a76-a4be-1006259aeaf2" finished successfully.

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.C.tfplan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_network.vpc will be created
  + resource "google_compute_network" "vpc" {
      + auto_create_subnetworks         = false
      + delete_default_routes_on_create = false
      + gateway_ipv4                    = (known after apply)
      + id                              = (known after apply)
      + internal_ipv6_range             = (known after apply)
      + mtu                             = (known after apply)
      + name                            = "gks-nowhere-vpc"
      + project                         = (known after apply)
      + routing_mode                    = (known after apply)
      + self_link                       = (known after apply)
    }

  # google_compute_subnetwork.subnet will be created
  + resource "google_compute_subnetwork" "subnet" {
      + creation_timestamp         = (known after apply)
      + external_ipv6_prefix       = (known after apply)
      + fingerprint                = (known after apply)
      + gateway_address            = (known after apply)
      + id                         = (known after apply)
      + ip_cidr_range              = "10.10.0.0/24"
      + ipv6_cidr_range            = (known after apply)
      + name                       = "gks-nowhere-subnet"
      + network                    = "gks-nowhere-vpc"
      + private_ipv6_google_access = (known after apply)
      + project                    = (known after apply)
      + purpose                    = (known after apply)
      + region                     = "us-east1"
      + secondary_ip_range         = (known after apply)
      + self_link                  = (known after apply)
      + stack_type                 = (known after apply)
    }

  # google_container_cluster.primary will be created
  + resource "google_container_cluster" "primary" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_legacy_abac          = false
      + enable_shielded_nodes       = true
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 1
      + label_fingerprint           = (known after apply)
      + location                    = "us-east1"
      + logging_service             = (known after apply)
      + master_version              = (known after apply)
      + monitoring_service          = (known after apply)
      + name                        = "gks-nowhere-gke"
      + network                     = "gks-nowhere-vpc"
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + remove_default_node_pool    = true
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = "gks-nowhere-subnet"
      + tpu_ipv4_cidr_block         = (known after apply)

      + addons_config {
          + cloudrun_config {
              + disabled           = (known after apply)
              + load_balancer_type = (known after apply)
            }

          + gcp_filestore_csi_driver_config {
              + enabled = (known after apply)
            }

          + horizontal_pod_autoscaling {
              + disabled = (known after apply)
            }

          + http_load_balancing {
              + disabled = (known after apply)
            }

          + network_policy_config {
              + disabled = (known after apply)
            }
        }

      + authenticator_groups_config {
          + security_group = (known after apply)
        }

      + cluster_autoscaling {
          + enabled = (known after apply)

          + auto_provisioning_defaults {
              + image_type      = (known after apply)
              + oauth_scopes    = (known after apply)
              + service_account = (known after apply)
            }

          + resource_limits {
              + maximum       = (known after apply)
              + minimum       = (known after apply)
              + resource_type = (known after apply)
            }
        }

      + confidential_nodes {
          + enabled = (known after apply)
        }

      + database_encryption {
          + key_name = (known after apply)
          + state    = (known after apply)
        }

      + default_snat_status {
          + disabled = (known after apply)
        }

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = (known after apply)
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = (known after apply)
          + services_secondary_range_name = (known after apply)
        }

      + logging_config {
          + enable_components = (known after apply)
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = (known after apply)
            }
        }

      + monitoring_config {
          + enable_components = (known after apply)
        }

      + node_config {
          + boot_disk_kms_key = (known after apply)
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + machine_type      = (known after apply)
          + metadata          = (known after apply)
          + min_cpu_platform  = (known after apply)
          + node_group        = (known after apply)
          + oauth_scopes      = (known after apply)
          + preemptible       = (known after apply)
          + service_account   = (known after apply)
          + spot              = (known after apply)
          + tags              = (known after apply)
          + taint             = (known after apply)

          + gcfs_config {
              + enabled = (known after apply)
            }

          + gvnic {
              + enabled = (known after apply)
            }

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + node_pool {
          + initial_node_count          = (known after apply)
          + instance_group_urls         = (known after apply)
          + managed_instance_group_urls = (known after apply)
          + max_pods_per_node           = (known after apply)
          + name                        = (known after apply)
          + name_prefix                 = (known after apply)
          + node_count                  = (known after apply)
          + node_locations              = (known after apply)
          + version                     = (known after apply)

          + autoscaling {
              + max_node_count = (known after apply)
              + min_node_count = (known after apply)
            }

          + management {
              + auto_repair  = (known after apply)
              + auto_upgrade = (known after apply)
            }

          + node_config {
              + boot_disk_kms_key = (known after apply)
              + disk_size_gb      = (known after apply)
              + disk_type         = (known after apply)
              + guest_accelerator = (known after apply)
              + image_type        = (known after apply)
              + labels            = (known after apply)
              + local_ssd_count   = (known after apply)
              + machine_type      = (known after apply)
              + metadata          = (known after apply)
              + min_cpu_platform  = (known after apply)
              + node_group        = (known after apply)
              + oauth_scopes      = (known after apply)
              + preemptible       = (known after apply)
              + service_account   = (known after apply)
              + spot              = (known after apply)
              + tags              = (known after apply)
              + taint             = (known after apply)

              + gcfs_config {
                  + enabled = (known after apply)
                }

              + gvnic {
                  + enabled = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + workload_metadata_config {
                  + mode = (known after apply)
                }
            }

          + upgrade_settings {
              + max_surge       = (known after apply)
              + max_unavailable = (known after apply)
            }
        }

      + release_channel {
          + channel = (known after apply)
        }

      + vertical_pod_autoscaling {
          + enabled = (known after apply)
        }

      + workload_identity_config {
          + workload_pool = (known after apply)
        }
    }

  # google_container_node_pool.primary_nodes will be created
  + resource "google_container_node_pool" "primary_nodes" {
      + cluster                     = "gks-nowhere-gke"
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "us-east1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = "gks-nowhere-gke"
      + name_prefix                 = (known after apply)
      + node_count                  = 2
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = (known after apply)

      + management {
          + auto_repair  = (known after apply)
          + auto_upgrade = (known after apply)
        }

      + node_config {
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = {
              + "env" = "gks-nowhere"
            }
          + local_ssd_count   = (known after apply)
          + machine_type      = "n1-standard-1"
          + metadata          = {
              + "disable-legacy-endpoints" = "true"
            }
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + tags              = [
              + "gke-node",
              + "gks-nowhere-gke",
            ]
          + taint             = (known after apply)

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + upgrade_settings {
          + max_surge       = (known after apply)
          + max_unavailable = (known after apply)
        }
    }

Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + kubernetes_cluster_host = (known after apply)
  + kubernetes_cluster_name = "gks-nowhere-gke"
  + project_id              = "gks-nowhere"
  + region                  = "us-east1"

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: PLAN.C.tfplan

To perform exactly these actions, run the following command to apply:
    terraform apply "PLAN.C.tfplan"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform apply "PLAN.C.tfplan"
google_compute_network.vpc: Creating...
google_compute_network.vpc: Still creating... [10s elapsed]
google_compute_network.vpc: Still creating... [20s elapsed]
google_compute_network.vpc: Creation complete after 23s [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_subnetwork.subnet: Creating...
google_compute_subnetwork.subnet: Still creating... [10s elapsed]
google_compute_subnetwork.subnet: Creation complete after 15s [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]
google_container_cluster.primary: Creating...
google_container_cluster.primary: Still creating... [10s elapsed]
google_container_cluster.primary: Still creating... [20s elapsed]
google_container_cluster.primary: Still creating... [30s elapsed]
google_container_cluster.primary: Still creating... [40s elapsed]
google_container_cluster.primary: Still creating... [50s elapsed]
google_container_cluster.primary: Still creating... [1m0s elapsed]
google_container_cluster.primary: Still creating... [1m10s elapsed]
google_container_cluster.primary: Still creating... [1m20s elapsed]
google_container_cluster.primary: Still creating... [1m30s elapsed]
google_container_cluster.primary: Still creating... [1m40s elapsed]
google_container_cluster.primary: Still creating... [1m50s elapsed]
google_container_cluster.primary: Still creating... [2m0s elapsed]
google_container_cluster.primary: Still creating... [2m10s elapsed]
google_container_cluster.primary: Still creating... [2m20s elapsed]
google_container_cluster.primary: Still creating... [2m30s elapsed]
google_container_cluster.primary: Still creating... [2m40s elapsed]
google_container_cluster.primary: Still creating... [2m50s elapsed]
google_container_cluster.primary: Still creating... [3m0s elapsed]
google_container_cluster.primary: Still creating... [3m10s elapsed]
google_container_cluster.primary: Still creating... [3m20s elapsed]
google_container_cluster.primary: Still creating... [3m30s elapsed]
google_container_cluster.primary: Still creating... [3m40s elapsed]
google_container_cluster.primary: Still creating... [3m50s elapsed]
google_container_cluster.primary: Still creating... [4m0s elapsed]
google_container_cluster.primary: Still creating... [4m10s elapsed]
google_container_cluster.primary: Still creating... [4m20s elapsed]
google_container_cluster.primary: Still creating... [4m30s elapsed]
google_container_cluster.primary: Still creating... [4m40s elapsed]
google_container_cluster.primary: Still creating... [4m50s elapsed]
google_container_cluster.primary: Still creating... [5m0s elapsed]
google_container_cluster.primary: Still creating... [5m11s elapsed]
google_container_cluster.primary: Still creating... [5m21s elapsed]
google_container_cluster.primary: Still creating... [5m31s elapsed]
google_container_cluster.primary: Still creating... [5m41s elapsed]
google_container_cluster.primary: Still creating... [5m51s elapsed]
google_container_cluster.primary: Still creating... [6m1s elapsed]
google_container_cluster.primary: Still creating... [6m11s elapsed]
google_container_cluster.primary: Still creating... [6m21s elapsed]
google_container_cluster.primary: Still creating... [6m31s elapsed]
google_container_cluster.primary: Still creating... [6m41s elapsed]
google_container_cluster.primary: Still creating... [6m51s elapsed]
google_container_cluster.primary: Still creating... [7m1s elapsed]
google_container_cluster.primary: Still creating... [7m11s elapsed]
google_container_cluster.primary: Still creating... [7m21s elapsed]
google_container_cluster.primary: Still creating... [7m31s elapsed]
google_container_cluster.primary: Still creating... [7m41s elapsed]
google_container_cluster.primary: Still creating... [7m51s elapsed]
google_container_cluster.primary: Still creating... [8m1s elapsed]
google_container_cluster.primary: Still creating... [8m11s elapsed]
google_container_cluster.primary: Still creating... [8m21s elapsed]
google_container_cluster.primary: Creation complete after 8m22s [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke]
google_container_node_pool.primary_nodes: Creating...
╷
│ Error: error creating NodePool: googleapi: Error 403: Insufficient regional quota to satisfy request: resource "SSD_TOTAL_GB": request requires '600.0' and is short '100.0'. project has a quota of '500.0' with '500.0' available. View and manage quotas at https://console.cloud.google.com/iam-admin/quotas?usage=USED&project=gks-nowhere., forbidden
│
│   with google_container_node_pool.primary_nodes,
│   on gke.tf line 32, in resource "google_container_node_pool" "primary_nodes":
│   32: resource "google_container_node_pool" "primary_nodes" {
│
╵
EPAM+Ethan_Li@EPCNSZXW0050 MINGW64 /d/dev/gcloud-k8s-terraform (main)
$ gcloud container clusters get-credentials $(terraform output -raw kubernetes_cluster_name) --region $(terraform output -raw region)
Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.
Fetching cluster endpoint and auth data.
CRITICAL: ACTION REQUIRED: gke-gcloud-auth-plugin, which is needed for continued use of kubectl, was not found or is not executable. Install gke-gcloud-auth-plugin for use with kubectl by following https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke
kubeconfig entry generated for gks-nowhere-gke.

EPAM+Ethan_Li@EPCNSZXW0050 MINGW64 /d/dev/gcloud-k8s-terraform (main)
$ terraform output -raw kubernetes_cluster_name
gks-nowhere-gke
EPAM+Ethan_Li@EPCNSZXW0050 MINGW64 /d/dev/gcloud-k8s-terraform (main)
$ terraform output -raw region
us-east1
EPAM+Ethan_Li@EPCNSZXW0050 MINGW64 /d/dev/gcloud-k8s-terraform (main)
$ date
Fri Feb 17 10:53:48 CST 2023

#  gcloud components install gke-gcloud-auth-plugin

Restarting command:
  $ gcloud components install gke-gcloud-auth-plugin

  $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml
  namespace/kubernetes-dashboard created
  serviceaccount/kubernetes-dashboard created
  service/kubernetes-dashboard created
  secret/kubernetes-dashboard-certs created
  secret/kubernetes-dashboard-csrf created
  secret/kubernetes-dashboard-key-holder created
  configmap/kubernetes-dashboard-settings created
  role.rbac.authorization.k8s.io/kubernetes-dashboard created
  clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
  rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
  clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
  Warning: spec.template.spec.nodeSelector[beta.kubernetes.io/os]: deprecated since v1.14; use "kubernetes.io/os" instead
  deployment.apps/kubernetes-dashboard created
  service/dashboard-metrics-scraper created
  Warning: spec.template.metadata.annotations[seccomp.security.alpha.kubernetes.io/pod]: deprecated since v1.19, non-functional in v1.25+; use the "seccompProfile" field instead
  deployment.apps/dashboard-metrics-scraper created

$ kubectl proxy
Starting to serve on 127.0.0.1:8001
http://127.0.0.1:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "no endpoints available for service \"kubernetes-dashboard\"",
  "reason": "ServiceUnavailable",
  "code": 503
}

$ terraform plan -out=PLAN.F.tfplan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_network.vpc will be created
  + resource "google_compute_network" "vpc" {
      + auto_create_subnetworks         = false
      + delete_default_routes_on_create = false
      + gateway_ipv4                    = (known after apply)
      + id                              = (known after apply)
      + internal_ipv6_range             = (known after apply)
      + mtu                             = (known after apply)
      + name                            = "gks-nowhere-vpc"
      + project                         = (known after apply)
      + routing_mode                    = (known after apply)
      + self_link                       = (known after apply)
    }

  # google_compute_subnetwork.subnet will be created
  + resource "google_compute_subnetwork" "subnet" {
      + creation_timestamp         = (known after apply)
      + external_ipv6_prefix       = (known after apply)
      + fingerprint                = (known after apply)
      + gateway_address            = (known after apply)
      + id                         = (known after apply)
      + ip_cidr_range              = "10.10.0.0/24"
      + ipv6_cidr_range            = (known after apply)
      + name                       = "gks-nowhere-subnet"
      + network                    = "gks-nowhere-vpc"
      + private_ipv6_google_access = (known after apply)
      + project                    = (known after apply)
      + purpose                    = (known after apply)
      + region                     = "us-east1"
      + secondary_ip_range         = (known after apply)
      + self_link                  = (known after apply)
      + stack_type                 = (known after apply)
    }

  # google_container_cluster.primary will be created
  + resource "google_container_cluster" "primary" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_legacy_abac          = false
      + enable_shielded_nodes       = true
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 1
      + label_fingerprint           = (known after apply)
      + location                    = "us-east1"
      + logging_service             = (known after apply)
      + master_version              = (known after apply)
      + monitoring_service          = (known after apply)
      + name                        = "gks-nowhere-gke"
      + network                     = "gks-nowhere-vpc"
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + remove_default_node_pool    = true
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = "gks-nowhere-subnet"
      + tpu_ipv4_cidr_block         = (known after apply)

      + addons_config {
          + cloudrun_config {
              + disabled           = (known after apply)
              + load_balancer_type = (known after apply)
            }

          + gcp_filestore_csi_driver_config {
              + enabled = (known after apply)
            }

          + horizontal_pod_autoscaling {
              + disabled = (known after apply)
            }

          + http_load_balancing {
              + disabled = (known after apply)
            }

          + network_policy_config {
              + disabled = (known after apply)
            }
        }

      + authenticator_groups_config {
          + security_group = (known after apply)
        }

      + cluster_autoscaling {
          + enabled = (known after apply)

          + auto_provisioning_defaults {
              + image_type      = (known after apply)
              + oauth_scopes    = (known after apply)
              + service_account = (known after apply)
            }

          + resource_limits {
              + maximum       = (known after apply)
              + minimum       = (known after apply)
              + resource_type = (known after apply)
            }
        }

      + confidential_nodes {
          + enabled = (known after apply)
        }

      + database_encryption {
          + key_name = (known after apply)
          + state    = (known after apply)
        }

      + default_snat_status {
          + disabled = (known after apply)
        }

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = (known after apply)
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = (known after apply)
          + services_secondary_range_name = (known after apply)
        }

      + logging_config {
          + enable_components = (known after apply)
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = (known after apply)
            }
        }

      + monitoring_config {
          + enable_components = (known after apply)
        }

      + node_config {
          + boot_disk_kms_key = (known after apply)
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + machine_type      = (known after apply)
          + metadata          = (known after apply)
          + min_cpu_platform  = (known after apply)
          + node_group        = (known after apply)
          + oauth_scopes      = (known after apply)
          + preemptible       = (known after apply)
          + service_account   = (known after apply)
          + spot              = (known after apply)
          + tags              = (known after apply)
          + taint             = (known after apply)

          + gcfs_config {
              + enabled = (known after apply)
            }

          + gvnic {
              + enabled = (known after apply)
            }

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + node_pool {
          + initial_node_count          = (known after apply)
          + instance_group_urls         = (known after apply)
          + managed_instance_group_urls = (known after apply)
          + max_pods_per_node           = (known after apply)
          + name                        = (known after apply)
          + name_prefix                 = (known after apply)
          + node_count                  = (known after apply)
          + node_locations              = (known after apply)
          + version                     = (known after apply)

          + autoscaling {
              + max_node_count = (known after apply)
              + min_node_count = (known after apply)
            }

          + management {
              + auto_repair  = (known after apply)
              + auto_upgrade = (known after apply)
            }

          + node_config {
              + boot_disk_kms_key = (known after apply)
              + disk_size_gb      = (known after apply)
              + disk_type         = (known after apply)
              + guest_accelerator = (known after apply)
              + image_type        = (known after apply)
              + labels            = (known after apply)
              + local_ssd_count   = (known after apply)
              + machine_type      = (known after apply)
              + metadata          = (known after apply)
              + min_cpu_platform  = (known after apply)
              + node_group        = (known after apply)
              + oauth_scopes      = (known after apply)
              + preemptible       = (known after apply)
              + service_account   = (known after apply)
              + spot              = (known after apply)
              + tags              = (known after apply)
              + taint             = (known after apply)

              + gcfs_config {
                  + enabled = (known after apply)
                }

              + gvnic {
                  + enabled = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + workload_metadata_config {
                  + mode = (known after apply)
                }
            }

          + upgrade_settings {
              + max_surge       = (known after apply)
              + max_unavailable = (known after apply)
            }
        }

      + release_channel {
          + channel = (known after apply)
        }

      + vertical_pod_autoscaling {
          + enabled = (known after apply)
        }

      + workload_identity_config {
          + workload_pool = (known after apply)
        }
    }

  # google_container_node_pool.primary_nodes will be created
  + resource "google_container_node_pool" "primary_nodes" {
      + cluster                     = "gks-nowhere-gke"
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "us-east1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = "gks-nowhere-gke"
      + name_prefix                 = (known after apply)
      + node_count                  = 1
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = (known after apply)

      + management {
          + auto_repair  = (known after apply)
          + auto_upgrade = (known after apply)
        }

      + node_config {
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = {
              + "env" = "gks-nowhere"
            }
          + local_ssd_count   = (known after apply)
          + machine_type      = "e2-small"
          + metadata          = {
              + "disable-legacy-endpoints" = "true"
            }
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + tags              = [
              + "gke-node",
              + "gks-nowhere-gke",
            ]
          + taint             = (known after apply)

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + upgrade_settings {
          + max_surge       = (known after apply)
          + max_unavailable = (known after apply)
        }
    }

Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + kubernetes_cluster_host = (known after apply)
  + kubernetes_cluster_name = "gks-nowhere-gke"
  + project_id              = "gks-nowhere"
  + region                  = "us-east1"

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: PLAN.F.tfplan

To perform exactly these actions, run the following command to apply:
    terraform apply "PLAN.F.tfplan"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform apply "PLAN.F.tfplan"
google_compute_network.vpc: Creating...
google_compute_network.vpc: Still creating... [10s elapsed]
google_compute_network.vpc: Still creating... [20s elapsed]
google_compute_network.vpc: Creation complete after 23s [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_subnetwork.subnet: Creating...
google_compute_subnetwork.subnet: Still creating... [10s elapsed]
google_compute_subnetwork.subnet: Creation complete after 14s [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]
google_container_cluster.primary: Creating...
google_container_cluster.primary: Still creating... [10s elapsed]
google_container_cluster.primary: Still creating... [20s elapsed]
google_container_cluster.primary: Still creating... [30s elapsed]
google_container_cluster.primary: Still creating... [40s elapsed]
google_container_cluster.primary: Still creating... [50s elapsed]
google_container_cluster.primary: Still creating... [1m0s elapsed]
google_container_cluster.primary: Still creating... [1m10s elapsed]
google_container_cluster.primary: Still creating... [1m20s elapsed]
google_container_cluster.primary: Still creating... [1m30s elapsed]
google_container_cluster.primary: Still creating... [1m40s elapsed]
google_container_cluster.primary: Still creating... [1m50s elapsed]
google_container_cluster.primary: Still creating... [2m0s elapsed]
google_container_cluster.primary: Still creating... [2m10s elapsed]
google_container_cluster.primary: Still creating... [2m20s elapsed]
google_container_cluster.primary: Still creating... [2m30s elapsed]
google_container_cluster.primary: Still creating... [2m40s elapsed]
google_container_cluster.primary: Still creating... [2m50s elapsed]
google_container_cluster.primary: Still creating... [3m0s elapsed]
google_container_cluster.primary: Still creating... [3m10s elapsed]
google_container_cluster.primary: Still creating... [3m20s elapsed]
google_container_cluster.primary: Still creating... [3m30s elapsed]
google_container_cluster.primary: Still creating... [3m40s elapsed]
google_container_cluster.primary: Still creating... [3m50s elapsed]
google_container_cluster.primary: Still creating... [4m0s elapsed]
google_container_cluster.primary: Still creating... [4m10s elapsed]
google_container_cluster.primary: Still creating... [4m20s elapsed]
google_container_cluster.primary: Still creating... [4m30s elapsed]
google_container_cluster.primary: Creation complete after 4m32s [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke]
google_container_node_pool.primary_nodes: Creating...
google_container_node_pool.primary_nodes: Still creating... [10s elapsed]
google_container_node_pool.primary_nodes: Still creating... [20s elapsed]
google_container_node_pool.primary_nodes: Still creating... [30s elapsed]
google_container_node_pool.primary_nodes: Still creating... [40s elapsed]
google_container_node_pool.primary_nodes: Still creating... [50s elapsed]
google_container_node_pool.primary_nodes: Still creating... [1m0s elapsed]
google_container_node_pool.primary_nodes: Creation complete after 1m8s [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke/nodePools/gks-nowhere-gke]

Apply complete! Resources: 4 added, 0 changed, 0 destroyed.

Outputs:

kubernetes_cluster_host = "34.74.150.249"
kubernetes_cluster_name = "gks-nowhere-gke"
project_id = "gks-nowhere"
region = "us-east1"

$ gcloud container clusters get-credentials $(terraform output -raw kubernetes_cluster_name) --region $(terraform output -raw region)
Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.
Fetching cluster endpoint and auth data.
kubeconfig entry generated for gks-nowhere-gke.

$ kubectl apply -f https://raw.githubusercontent.com/hashicorp/learn-terraform-provision-gke-cluster/main/kubernetes-dashboard-admin.rbac.yaml
serviceaccount/admin-user created
clusterrolebinding.rbac.authorization.k8s.io/admin-user created

Ethan_Li@EPCNSZXW0050 C:\Users\Ethan_Li

$ gcloud container clusters describe gks-nowhere-gke --region us-east1
addonsConfig:
  gcePersistentDiskCsiDriverConfig:
    enabled: true
  kubernetesDashboard:
    disabled: true
  networkPolicyConfig:
    disabled: true
autopilot: {}
autoscaling:
  autoscalingProfile: BALANCED
binaryAuthorization: {}
clusterIpv4Cidr: 10.220.0.0/14
createTime: '2023-02-17T03:18:24+00:00'
currentMasterVersion: 1.24.9-gke.2000
currentNodeCount: 3
currentNodeVersion: 1.24.9-gke.2000
databaseEncryption:
  state: DECRYPTED
endpoint: 34.74.150.249
etag: fc91fe5e-73b1-4934-b815-eab012a6299d
id: 8c797a95450d4c2ba59254412db785ad8ba23731a379422c9ac776feb75a3307
initialClusterVersion: 1.24.9-gke.2000
initialNodeCount: 1
instanceGroupUrls:
- https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-b/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-5f220a3d-grp
- https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-d/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-870ab46d-grp
- https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-c/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-a957fb0b-grp
ipAllocationPolicy:
  stackType: IPV4
  useRoutes: true
labelFingerprint: a9dc16a7
legacyAbac: {}
location: us-east1
locations:
- us-east1-b
- us-east1-d
- us-east1-c
loggingConfig:
  componentConfig:
    enableComponents:
    - SYSTEM_COMPONENTS
    - WORKLOADS
loggingService: logging.googleapis.com/kubernetes
maintenancePolicy:
  resourceVersion: e3b0c442
masterAuth:
  clusterCaCertificate: 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
masterAuthorizedNetworksConfig:
  gcpPublicCidrsAccessEnabled: true
monitoringConfig:
  componentConfig:
    enableComponents:
    - SYSTEM_COMPONENTS
monitoringService: monitoring.googleapis.com/kubernetes
name: gks-nowhere-gke
network: gks-nowhere-vpc
networkConfig:
  defaultSnatStatus: {}
  network: projects/gks-nowhere/global/networks/gks-nowhere-vpc
  serviceExternalIpsConfig: {}
  subnetwork: projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet
nodeConfig:
  diskSizeGb: 100
  diskType: pd-balanced
  imageType: COS_CONTAINERD
  labels:
    env: gks-nowhere
  machineType: e2-small
  metadata:
    disable-legacy-endpoints: 'true'
  oauthScopes:
  - https://www.googleapis.com/auth/monitoring
  - https://www.googleapis.com/auth/logging.write
  serviceAccount: default
  shieldedInstanceConfig:
    enableIntegrityMonitoring: true
  tags:
  - gke-node
  - gks-nowhere-gke
  windowsNodeConfig: {}
nodeIpv4CidrSize: 24
nodePoolAutoConfig: {}
nodePoolDefaults:
  nodeConfigDefaults:
    loggingConfig:
      variantConfig:
        variant: DEFAULT
nodePools:
- config:
    diskSizeGb: 100
    diskType: pd-balanced
    imageType: COS_CONTAINERD
    labels:
      env: gks-nowhere
    machineType: e2-small
    metadata:
      disable-legacy-endpoints: 'true'
    oauthScopes:
    - https://www.googleapis.com/auth/monitoring
    - https://www.googleapis.com/auth/logging.write
    serviceAccount: default
    shieldedInstanceConfig:
      enableIntegrityMonitoring: true
    tags:
    - gke-node
    - gks-nowhere-gke
    windowsNodeConfig: {}
  etag: f6636448-073e-4b74-ac13-fa999a7d6f77
  initialNodeCount: 1
  instanceGroupUrls:
  - https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-b/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-5f220a3d-grp
  - https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-d/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-870ab46d-grp
  - https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-c/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-a957fb0b-grp
  locations:
  - us-east1-b
  - us-east1-d
  - us-east1-c
  management:
    autoRepair: true
    autoUpgrade: true
  name: gks-nowhere-gke
  networkConfig:
    enablePrivateNodes: false
  podIpv4CidrSize: 24
  selfLink: https://container.googleapis.com/v1/projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke/nodePools/gks-nowhere-gke
  status: RUNNING
  upgradeSettings:
    maxSurge: 1
    strategy: SURGE
  version: 1.24.9-gke.2000
notificationConfig:
  pubsub: {}
privateClusterConfig:
  privateEndpoint: 10.10.0.2
  publicEndpoint: 34.74.150.249
releaseChannel:
  channel: REGULAR
selfLink: https://container.googleapis.com/v1/projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke
servicesIpv4Cidr: 10.223.240.0/20
shieldedNodes:
  enabled: true
status: RUNNING
subnetwork: gks-nowhere-subnet
zone: us-east1


Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ kubectl proxy
Starting to serve on 127.0.0.1:8001
E0217 12:59:23.937178   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:23.954265   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:23.957236   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:23.958024   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:23.958543   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:28.938054   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:28.940719   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:28.943872   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:28.945931   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:28.950207   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:33.947583   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:33.952489   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:33.954234   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:33.955446   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:33.955953   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:34.552964   30060 proxy_server.go:147] Error while proxying request: dial tcp 34.74.150.249:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.
E0217 12:59:34.592358   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:34.593386   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:34.593386   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:34.593386   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:34.593386   30060 proxy_server.go:147] Error while proxying request: context canceled
E0217 12:59:34.593386   30060 proxy_server.go:147] Error while proxying request: context canceled
^C
Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform apply "PLAN.F.tfplan"
╷
│ Error: Saved plan is stale
│
│ The given plan file can no longer be applied because the state was changed by another operation after the plan was created.
╵

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ ratera

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terrafpr, [

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform plan -out=PLAN.F.tfplan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_network.vpc will be created
  + resource "google_compute_network" "vpc" {
      + auto_create_subnetworks         = false
      + delete_default_routes_on_create = false
      + gateway_ipv4                    = (known after apply)
      + id                              = (known after apply)
      + internal_ipv6_range             = (known after apply)
      + mtu                             = (known after apply)
      + name                            = "gks-nowhere-vpc"
      + project                         = (known after apply)
      + routing_mode                    = (known after apply)
      + self_link                       = (known after apply)
    }

  # google_compute_subnetwork.subnet will be created
  + resource "google_compute_subnetwork" "subnet" {
      + creation_timestamp         = (known after apply)
      + external_ipv6_prefix       = (known after apply)
      + fingerprint                = (known after apply)
      + gateway_address            = (known after apply)
      + id                         = (known after apply)
      + ip_cidr_range              = "10.10.0.0/24"
      + ipv6_cidr_range            = (known after apply)
      + name                       = "gks-nowhere-subnet"
      + network                    = "gks-nowhere-vpc"
      + private_ipv6_google_access = (known after apply)
      + project                    = (known after apply)
      + purpose                    = (known after apply)
      + region                     = "us-east1"
      + secondary_ip_range         = (known after apply)
      + self_link                  = (known after apply)
      + stack_type                 = (known after apply)
    }

  # google_container_cluster.primary will be created
  + resource "google_container_cluster" "primary" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_legacy_abac          = false
      + enable_shielded_nodes       = true
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 1
      + label_fingerprint           = (known after apply)
      + location                    = "us-east1"
      + logging_service             = (known after apply)
      + master_version              = (known after apply)
      + monitoring_service          = (known after apply)
      + name                        = "gks-nowhere-gke"
      + network                     = "gks-nowhere-vpc"
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + remove_default_node_pool    = true
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = "gks-nowhere-subnet"
      + tpu_ipv4_cidr_block         = (known after apply)

      + addons_config {
          + cloudrun_config {
              + disabled           = (known after apply)
              + load_balancer_type = (known after apply)
            }

          + gcp_filestore_csi_driver_config {
              + enabled = (known after apply)
            }

          + horizontal_pod_autoscaling {
              + disabled = (known after apply)
            }

          + http_load_balancing {
              + disabled = (known after apply)
            }

          + network_policy_config {
              + disabled = (known after apply)
            }
        }

      + authenticator_groups_config {
          + security_group = (known after apply)
        }

      + cluster_autoscaling {
          + enabled = (known after apply)

          + auto_provisioning_defaults {
              + image_type      = (known after apply)
              + oauth_scopes    = (known after apply)
              + service_account = (known after apply)
            }

          + resource_limits {
              + maximum       = (known after apply)
              + minimum       = (known after apply)
              + resource_type = (known after apply)
            }
        }

      + confidential_nodes {
          + enabled = (known after apply)
        }

      + database_encryption {
          + key_name = (known after apply)
          + state    = (known after apply)
        }

      + default_snat_status {
          + disabled = (known after apply)
        }

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = (known after apply)
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = (known after apply)
          + services_secondary_range_name = (known after apply)
        }

      + logging_config {
          + enable_components = (known after apply)
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = (known after apply)
            }
        }

      + monitoring_config {
          + enable_components = (known after apply)
        }

      + node_config {
          + boot_disk_kms_key = (known after apply)
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + machine_type      = (known after apply)
          + metadata          = (known after apply)
          + min_cpu_platform  = (known after apply)
          + node_group        = (known after apply)
          + oauth_scopes      = (known after apply)
          + preemptible       = (known after apply)
          + service_account   = (known after apply)
          + spot              = (known after apply)
          + tags              = (known after apply)
          + taint             = (known after apply)

          + gcfs_config {
              + enabled = (known after apply)
            }

          + gvnic {
              + enabled = (known after apply)
            }

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + node_pool {
          + initial_node_count          = (known after apply)
          + instance_group_urls         = (known after apply)
          + managed_instance_group_urls = (known after apply)
          + max_pods_per_node           = (known after apply)
          + name                        = (known after apply)
          + name_prefix                 = (known after apply)
          + node_count                  = (known after apply)
          + node_locations              = (known after apply)
          + version                     = (known after apply)

          + autoscaling {
              + max_node_count = (known after apply)
              + min_node_count = (known after apply)
            }

          + management {
              + auto_repair  = (known after apply)
              + auto_upgrade = (known after apply)
            }

          + node_config {
              + boot_disk_kms_key = (known after apply)
              + disk_size_gb      = (known after apply)
              + disk_type         = (known after apply)
              + guest_accelerator = (known after apply)
              + image_type        = (known after apply)
              + labels            = (known after apply)
              + local_ssd_count   = (known after apply)
              + machine_type      = (known after apply)
              + metadata          = (known after apply)
              + min_cpu_platform  = (known after apply)
              + node_group        = (known after apply)
              + oauth_scopes      = (known after apply)
              + preemptible       = (known after apply)
              + service_account   = (known after apply)
              + spot              = (known after apply)
              + tags              = (known after apply)
              + taint             = (known after apply)

              + gcfs_config {
                  + enabled = (known after apply)
                }

              + gvnic {
                  + enabled = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + workload_metadata_config {
                  + mode = (known after apply)
                }
            }

          + upgrade_settings {
              + max_surge       = (known after apply)
              + max_unavailable = (known after apply)
            }
        }

      + release_channel {
          + channel = (known after apply)
        }

      + vertical_pod_autoscaling {
          + enabled = (known after apply)
        }

      + workload_identity_config {
          + workload_pool = (known after apply)
        }
    }

  # google_container_node_pool.primary_nodes will be created
  + resource "google_container_node_pool" "primary_nodes" {
      + cluster                     = "gks-nowhere-gke"
      + id                          = (known after apply)
      + initial_node_count          = (known after apply)
      + instance_group_urls         = (known after apply)
      + location                    = "us-east1"
      + managed_instance_group_urls = (known after apply)
      + max_pods_per_node           = (known after apply)
      + name                        = "gks-nowhere-gke"
      + name_prefix                 = (known after apply)
      + node_count                  = 1
      + node_locations              = (known after apply)
      + operation                   = (known after apply)
      + project                     = (known after apply)
      + version                     = (known after apply)

      + management {
          + auto_repair  = (known after apply)
          + auto_upgrade = (known after apply)
        }

      + node_config {
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = {
              + "env" = "gks-nowhere"
            }
          + local_ssd_count   = (known after apply)
          + machine_type      = "e2-small"
          + metadata          = {
              + "disable-legacy-endpoints" = "true"
            }
          + oauth_scopes      = [
              + "https://www.googleapis.com/auth/logging.write",
              + "https://www.googleapis.com/auth/monitoring",
            ]
          + preemptible       = false
          + service_account   = (known after apply)
          + spot              = false
          + tags              = [
              + "gke-node",
              + "gks-nowhere-gke",
            ]
          + taint             = (known after apply)

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + upgrade_settings {
          + max_surge       = (known after apply)
          + max_unavailable = (known after apply)
        }
    }

Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + kubernetes_cluster_host = (known after apply)
  + kubernetes_cluster_name = "gks-nowhere-gke"
  + project_id              = "gks-nowhere"
  + region                  = "us-east1"

───────────────────────────────────────────────────────────────────────────────────────────────────────────
───────────────────────────────────────────────────────────────────────────────────

Saved the plan to: PLAN.F.tfplan

To perform exactly these actions, run the following command to apply:
    terraform apply "PLAN.F.tfplan"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform apply PLAN.F.tfplan
google_compute_network.vpc: Creating...
google_compute_network.vpc: Still creating... [10s elapsed]
google_compute_network.vpc: Creation complete after 12s [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_subnetwork.subnet: Creating...
google_compute_subnetwork.subnet: Still creating... [10s elapsed]
google_compute_subnetwork.subnet: Creation complete after 15s [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]
google_container_cluster.primary: Creating...
google_container_cluster.primary: Still creating... [10s elapsed]
google_container_cluster.primary: Still creating... [20s elapsed]
google_container_cluster.primary: Still creating... [30s elapsed]
google_container_cluster.primary: Still creating... [40s elapsed]
google_container_cluster.primary: Still creating... [50s elapsed]
google_container_cluster.primary: Still creating... [1m0s elapsed]
google_container_cluster.primary: Still creating... [1m10s elapsed]
google_container_cluster.primary: Still creating... [1m20s elapsed]
google_container_cluster.primary: Still creating... [1m30s elapsed]
google_container_cluster.primary: Still creating... [1m40s elapsed]
google_container_cluster.primary: Still creating... [1m50s elapsed]
google_container_cluster.primary: Still creating... [2m0s elapsed]
google_container_cluster.primary: Still creating... [2m10s elapsed]
google_container_cluster.primary: Still creating... [2m20s elapsed]
google_container_cluster.primary: Still creating... [2m30s elapsed]
google_container_cluster.primary: Still creating... [2m40s elapsed]
google_container_cluster.primary: Still creating... [2m50s elapsed]
google_container_cluster.primary: Still creating... [3m0s elapsed]
google_container_cluster.primary: Still creating... [3m10s elapsed]
google_container_cluster.primary: Still creating... [3m20s elapsed]
google_container_cluster.primary: Still creating... [3m30s elapsed]
google_container_cluster.primary: Still creating... [3m40s elapsed]
google_container_cluster.primary: Still creating... [3m50s elapsed]
google_container_cluster.primary: Still creating... [4m0s elapsed]
google_container_cluster.primary: Still creating... [4m10s elapsed]
google_container_cluster.primary: Still creating... [4m20s elapsed]
google_container_cluster.primary: Still creating... [4m30s elapsed]
google_container_cluster.primary: Still creating... [4m40s elapsed]
google_container_cluster.primary: Still creating... [4m50s elapsed]
google_container_cluster.primary: Creation complete after 4m54s [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke]
google_container_node_pool.primary_nodes: Creating...
google_container_node_pool.primary_nodes: Still creating... [10s elapsed]
google_container_node_pool.primary_nodes: Still creating... [20s elapsed]
google_container_node_pool.primary_nodes: Still creating... [30s elapsed]
google_container_node_pool.primary_nodes: Still creating... [40s elapsed]
google_container_node_pool.primary_nodes: Still creating... [50s elapsed]
google_container_node_pool.primary_nodes: Creation complete after 58s [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke/nodePools/gks-nowhere-gke]

Apply complete! Resources: 4 added, 0 changed, 0 destroyed.

Outputs:

kubernetes_cluster_host = "34.139.12.54"
kubernetes_cluster_name = "gks-nowhere-gke"
project_id = "gks-nowhere"
region = "us-east1"

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml
namespace/kubernetes-dashboard created
serviceaccount/kubernetes-dashboard created
service/kubernetes-dashboard created
secret/kubernetes-dashboard-certs created
secret/kubernetes-dashboard-csrf created
secret/kubernetes-dashboard-key-holder created
configmap/kubernetes-dashboard-settings created
role.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
Warning: spec.template.spec.nodeSelector[beta.kubernetes.io/os]: deprecated since v1.14; use "kubernetes.io/os" instead
deployment.apps/kubernetes-dashboard created
service/dashboard-metrics-scraper created
Warning: spec.template.metadata.annotations[seccomp.security.alpha.kubernetes.io/pod]: deprecated since v1.19, non-functional in v1.25+; use the "seccompProfile" field instead
deployment.apps/dashboard-metrics-scraper created

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ kubectl proxy
Starting to serve on 127.0.0.1:8001
E0217 16:07:27.620538   29464 proxy_server.go:147] Error while proxying request: context canceled
E0217 17:10:50.386996   29464 proxy_server.go:147] Error while proxying request: context canceled
^C
Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform destroy -auto-approver
╷
│ Error: Failed to parse command-line flags
│
│ flag provided but not defined: -auto-approver
╵

For more help on using this command, run:
  terraform destroy -help

Ethan_Li@EPCNSZXW0050 D:\dev\gcloud-k8s-terraform
$ terraform destroy -auto-approve
google_compute_network.vpc: Refreshing state... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_subnetwork.subnet: Refreshing state... [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]
google_container_cluster.primary: Refreshing state... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke]
google_container_node_pool.primary_nodes: Refreshing state... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke/nodePools/gks-nowhere-gke]

Terraform used the selected providers to generate the following execution plan. Resource actions are
indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # google_compute_network.vpc will be destroyed
  - resource "google_compute_network" "vpc" {
      - auto_create_subnetworks         = false -> null
      - delete_default_routes_on_create = false -> null
      - enable_ula_internal_ipv6        = false -> null
      - id                              = "projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
      - mtu                             = 0 -> null
      - name                            = "gks-nowhere-vpc" -> null
      - project                         = "gks-nowhere" -> null
      - routing_mode                    = "REGIONAL" -> null
      - self_link                       = "https://www.googleapis.com/compute/v1/projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
    }

  # google_compute_subnetwork.subnet will be destroyed
  - resource "google_compute_subnetwork" "subnet" {
      - creation_timestamp         = "2023-02-16T21:57:00.431-08:00" -> null
      - gateway_address            = "10.10.0.1" -> null
      - id                         = "projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet" -> null
      - ip_cidr_range              = "10.10.0.0/24" -> null
      - name                       = "gks-nowhere-subnet" -> null
      - network                    = "https://www.googleapis.com/compute/v1/projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
      - private_ip_google_access   = true -> null
      - private_ipv6_google_access = "DISABLE_GOOGLE_ACCESS" -> null
      - project                    = "gks-nowhere" -> null
      - purpose                    = "PRIVATE" -> null
      - region                     = "us-east1" -> null
      - secondary_ip_range         = [] -> null
      - self_link                  = "https://www.googleapis.com/compute/v1/projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet" -> null
      - stack_type                 = "IPV4_ONLY" -> null
    }

  # google_container_cluster.primary will be destroyed
  - resource "google_container_cluster" "primary" {
      - cluster_ipv4_cidr           = "10.220.0.0/14" -> null
      - enable_autopilot            = false -> null
      - enable_binary_authorization = false -> null
      - enable_intranode_visibility = false -> null
      - enable_kubernetes_alpha     = false -> null
      - enable_legacy_abac          = false -> null
      - enable_shielded_nodes       = true -> null
      - enable_tpu                  = false -> null
      - endpoint                    = "34.139.12.54" -> null
      - id                          = "projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke" -> null
      - initial_node_count          = 1 -> null
      - label_fingerprint           = "a9dc16a7" -> null
      - location                    = "us-east1" -> null
      - logging_service             = "logging.googleapis.com/kubernetes" -> null
      - master_version              = "1.24.9-gke.2000" -> null
      - monitoring_service          = "monitoring.googleapis.com/kubernetes" -> null
      - name                        = "gks-nowhere-gke" -> null
      - network                     = "projects/gks-nowhere/global/networks/gks-nowhere-vpc" -> null
      - networking_mode             = "ROUTES" -> null
      - node_locations              = [
          - "us-east1-b",
          - "us-east1-c",
          - "us-east1-d",
        ] -> null
      - node_version                = "1.24.9-gke.2000" -> null
      - project                     = "gks-nowhere" -> null
      - remove_default_node_pool    = true -> null
      - resource_labels             = {} -> null
      - self_link                   = "https://container.googleapis.com/v1/projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke" -> null
      - services_ipv4_cidr          = "10.223.240.0/20" -> null
      - subnetwork                  = "projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet" -> null

      - addons_config {

          - network_policy_config {
              - disabled = true -> null
            }
        }

      - cluster_autoscaling {
          - enabled = false -> null
        }

      - database_encryption {
          - state = "DECRYPTED" -> null
        }

      - default_snat_status {
          - disabled = false -> null
        }

      - logging_config {
          - enable_components = [
              - "SYSTEM_COMPONENTS",
              - "WORKLOADS",
            ] -> null
        }

      - master_auth {
          - cluster_ca_certificate = "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVMRENDQXBTZ0F3SUJBZ0lRU0cyU2FoVkhuSTZQdmdKcXlFQllYekFOQmdrcWhraUc5dzBCQVFzRkFEQXYKTVMwd0t3WURWUVFERXlSbE1XTTFZVE5qTWkxa04yVXdMVFF3T0RBdE9UaGtNQzB5WmpjNE5tUXdabU5pWVRNdwpJQmNOTWpNd01qRTNNRFExTnpFMVdoZ1BNakExTXpBeU1Ea3dOVFUzTVRWYU1DOHhMVEFyQmdOVkJBTVRKR1V4Cll6VmhNMk15TFdRM1pUQXROREE0TUMwNU9HUXdMVEptTnpnMlpEQm1ZMkpoTXpDQ0FhSXdEUVlKS29aSWh2Y04KQVFFQkJRQURnZ0dQQURDQ0FZb0NnZ0dCQUx6TW5ncWIyMGltcU1YYUl4MXp5L0VpdnZMTVBVT1MwVlI0VHpQcQpjY0Y1ZzUwSXdwaEtqakFtTWJEa2J6Y0QyWnVBZUo4cWF6eGRsMGhpT0orNWZXRC9KQXVxcjYzZnB5RFAzalJmCmUrWlF6aEt0WVRqa1JSd2dYaHB0UW9qTGRzbGd2VDlRVGtULzd3bTU2ZENOSlo0Um1yZWQ5NTVLQ0NDeVFaTXkKYlVISXJVL3Y0UTZ1WUpjN1BGUGpTS2JnY1hwYlNGQTcxZHBUVlRvUk03N2o2bXlYV2l6ZWlJRmxwZUdmOXJUNQp2KzFhSlU5WnBUdTVaaTBNYUNWc3NRcDdNd1BrVmtBZUtiVHdsMDZXWnZETTRjNUt3S291bDlXZGpKcnJTUENICnNWNFVVTFo2MGVZVXRvQzRHaEZvQWVTZ1NQdlhFRDE4cFFiNktzNG1WREJHbkxnMmRRc1FxNTlTWis5Q21ZeHcKN05RaUNwMXRQUkU1WE10Z0ZmVTBBUVhjeFBJOC9CQ2hQMndxVlM3V2pDcWZQRnBOU3NQVCtVV0tQcUJEOFBHcApkYU1FRHN3OE5lUFhzMEFwSnRocitCb0RXQUJ3SjluVEJxd05kc3R5TnlXdjUwTWN4endNNDZzZEJSV1RmdXllCjh5SXZCOUhaSW1zVDJiQzFybkxGWnhIdGpRSURBUUFCbzBJd1FEQU9CZ05WSFE4QkFmOEVCQU1DQWdRd0R3WUQKVlIwVEFRSC9CQVV3QXdFQi96QWRCZ05WSFE0RUZnUVV4NUdmN2Zkbk5Wb0hsMDB6NkJTcDVMV0VvbE13RFFZSgpLb1pJaHZjTkFRRUxCUUFEZ2dHQkFLUmtiUjIrQTgvczJOTGJCU2EvelR1eHZaVGlJamlzRXdWdTVzdkkrbE5YCktoTHhBMVlVcFkyZlR2YUxyekZvYTJ5d3pSb2p1akJSbmU1UmtwREhoR1Nwd3ZKaHFNUjhxQTdvV0QrUFVTclIKc2RobVJScDdYQUl5TDNJL0l6YnNKS0hJV1czM3RRQ0doUjRzNVdtRWRBRndBVGdvVVcxK2VLaUpiOUJTbVVYawp0SU12ZkFUVHNWN2hJNVBCdHl6cmlCL0RudzcyQlMrSlpKOW9nQTFGM2tPSHlvZkVUbnVYTWI4a04yR0VNUnBRCkNxMDRjWjF6dlluYXZEdmJxZlFabncrUTdMQ0RjdG1PUUJ3U2NlWEpHZy9wNjlvVEx1NFdJaDhEZVA4Y1VPamkKTkkxbkd2aXpvdDZNYngyNjVuMCt1NUE2Rm14U2d1d2hqcmdPMUprUXpUYzd4WWJCZDMvSVR2eTFDdktycnA3awpNYy9KZEpCNlRRQWRwUFpGUzhKWFhybmVxemhPelF2UUpLekZHa0JSRDhxZ1huUjFpVjdGOUpFUDNKZ2JCOW9FCk1DelZTeWhGbWg4bjdUaXBwZnBTcysxcmRFMk1ScGpob0JGRWJLVGhnYzBUZ2VtV0tmeStOTk1uOW9idTFRQUEKTTJkWDNzTWFWWkw0dkdiNTJOb2Rjdz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K" -> null

          - client_certificate_config {
              - issue_client_certificate = false -> null
            }
        }

      - monitoring_config {
          - enable_components = [
              - "SYSTEM_COMPONENTS",
            ] -> null
        }

      - network_policy {
          - enabled  = false -> null
          - provider = "PROVIDER_UNSPECIFIED" -> null
        }

      - node_config {
          - disk_size_gb      = 100 -> null
          - disk_type         = "pd-balanced" -> null
          - guest_accelerator = [] -> null
          - image_type        = "COS_CONTAINERD" -> null
          - labels            = {
              - "env" = "gks-nowhere"
            } -> null
          - local_ssd_count   = 0 -> null
          - machine_type      = "e2-small" -> null
          - metadata          = {
              - "disable-legacy-endpoints" = "true"
            } -> null
          - oauth_scopes      = [
              - "https://www.googleapis.com/auth/logging.write",
              - "https://www.googleapis.com/auth/monitoring",
            ] -> null
          - preemptible       = false -> null
          - service_account   = "default" -> null
          - spot              = false -> null
          - tags              = [
              - "gke-node",
              - "gks-nowhere-gke",
            ] -> null
          - taint             = [] -> null

          - shielded_instance_config {
              - enable_integrity_monitoring = true -> null
              - enable_secure_boot          = false -> null
            }
        }

      - node_pool {
          - initial_node_count          = 1 -> null
          - instance_group_urls         = [
              - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-c/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-d654c491-grp",
              - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-d/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-6eba5cfd-grp",
              - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-b/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-ce13b02b-grp",
            ] -> null
          - managed_instance_group_urls = [
              - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-c/instanceGroups/gke-gks-nowhere-gke-gks-nowhere-gke-d654c491-grp",
              - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-d/instanceGroups/gke-gks-nowhere-gke-gks-nowhere-gke-6eba5cfd-grp",
              - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-b/instanceGroups/gke-gks-nowhere-gke-gks-nowhere-gke-ce13b02b-grp",
            ] -> null
          - max_pods_per_node           = 0 -> null
          - name                        = "gks-nowhere-gke" -> null
          - node_count                  = 1 -> null
          - node_locations              = [
              - "us-east1-b",
              - "us-east1-c",
              - "us-east1-d",
            ] -> null
          - version                     = "1.24.9-gke.2000" -> null

          - management {
              - auto_repair  = true -> null
              - auto_upgrade = true -> null
            }

          - node_config {
              - disk_size_gb      = 100 -> null
              - disk_type         = "pd-balanced" -> null
              - guest_accelerator = [] -> null
              - image_type        = "COS_CONTAINERD" -> null
              - labels            = {
                  - "env" = "gks-nowhere"
                } -> null
              - local_ssd_count   = 0 -> null
              - machine_type      = "e2-small" -> null
              - metadata          = {
                  - "disable-legacy-endpoints" = "true"
                } -> null
              - oauth_scopes      = [
                  - "https://www.googleapis.com/auth/logging.write",
                  - "https://www.googleapis.com/auth/monitoring",
                ] -> null
              - preemptible       = false -> null
              - service_account   = "default" -> null
              - spot              = false -> null
              - tags              = [
                  - "gke-node",
                  - "gks-nowhere-gke",
                ] -> null
              - taint             = [] -> null

              - shielded_instance_config {
                  - enable_integrity_monitoring = true -> null
                  - enable_secure_boot          = false -> null
                }
            }

          - upgrade_settings {
              - max_surge       = 1 -> null
              - max_unavailable = 0 -> null
            }
        }

      - private_cluster_config {
          - enable_private_endpoint = false -> null
          - enable_private_nodes    = false -> null
          - private_endpoint        = "10.10.0.2" -> null
          - public_endpoint         = "34.139.12.54" -> null

          - master_global_access_config {
              - enabled = false -> null
            }
        }

      - release_channel {
          - channel = "REGULAR" -> null
        }
    }

  # google_container_node_pool.primary_nodes will be destroyed
  - resource "google_container_node_pool" "primary_nodes" {
      - cluster                     = "gks-nowhere-gke" -> null
      - id                          = "projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke/nodePools/gks-nowhere-gke" -> null
      - initial_node_count          = 1 -> null
      - instance_group_urls         = [
          - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-c/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-d654c491-grp",
          - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-d/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-6eba5cfd-grp",
          - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-b/instanceGroupManagers/gke-gks-nowhere-gke-gks-nowhere-gke-ce13b02b-grp",
        ] -> null
      - location                    = "us-east1" -> null
      - managed_instance_group_urls = [
          - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-c/instanceGroups/gke-gks-nowhere-gke-gks-nowhere-gke-d654c491-grp",
          - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-d/instanceGroups/gke-gks-nowhere-gke-gks-nowhere-gke-6eba5cfd-grp",
          - "https://www.googleapis.com/compute/v1/projects/gks-nowhere/zones/us-east1-b/instanceGroups/gke-gks-nowhere-gke-gks-nowhere-gke-ce13b02b-grp",
        ] -> null
      - name                        = "gks-nowhere-gke" -> null
      - node_count                  = 1 -> null
      - node_locations              = [
          - "us-east1-b",
          - "us-east1-c",
          - "us-east1-d",
        ] -> null
      - project                     = "gks-nowhere" -> null
      - version                     = "1.24.9-gke.2000" -> null

      - management {
          - auto_repair  = true -> null
          - auto_upgrade = true -> null
        }

      - node_config {
          - disk_size_gb      = 100 -> null
          - disk_type         = "pd-balanced" -> null
          - guest_accelerator = [] -> null
          - image_type        = "COS_CONTAINERD" -> null
          - labels            = {
              - "env" = "gks-nowhere"
            } -> null
          - local_ssd_count   = 0 -> null
          - machine_type      = "e2-small" -> null
          - metadata          = {
              - "disable-legacy-endpoints" = "true"
            } -> null
          - oauth_scopes      = [
              - "https://www.googleapis.com/auth/logging.write",
              - "https://www.googleapis.com/auth/monitoring",
            ] -> null
          - preemptible       = false -> null
          - service_account   = "default" -> null
          - spot              = false -> null
          - tags              = [
              - "gke-node",
              - "gks-nowhere-gke",
            ] -> null
          - taint             = [] -> null

          - shielded_instance_config {
              - enable_integrity_monitoring = true -> null
              - enable_secure_boot          = false -> null
            }
        }

      - upgrade_settings {
          - max_surge       = 1 -> null
          - max_unavailable = 0 -> null
        }
    }

Plan: 0 to add, 0 to change, 4 to destroy.

Changes to Outputs:
  - kubernetes_cluster_host = "34.139.12.54" -> null
  - kubernetes_cluster_name = "gks-nowhere-gke" -> null
  - project_id              = "gks-nowhere" -> null
  - region                  = "us-east1" -> null
google_container_node_pool.primary_nodes: Destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke/nodePools/gks-nowhere-gke]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 10s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 20s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 30s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 40s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 50s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 1m0s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 1m10s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 1m20s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 1m30s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 1m40s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 1m50s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 2m0s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 2m10s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 2m20s elapsed]
google_container_node_pool.primary_nodes: Still destroying... [id=projects/gks-nowhere/locations/us-east1...-nowhere-gke/nodePools/gks-nowhere-gke, 2m30s elapsed]
google_container_node_pool.primary_nodes: Destruction complete after 2m35s
google_container_cluster.primary: Destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 1m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 1m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 1m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 1m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 1m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 1m50s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 2m0s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 2m10s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 2m20s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 2m30s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 2m40s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 2m51s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 3m1s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 3m11s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 3m21s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 3m31s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 3m41s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 3m51s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 4m1s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 4m11s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 4m21s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 4m31s elapsed]
google_container_cluster.primary: Still destroying... [id=projects/gks-nowhere/locations/us-east1/clusters/gks-nowhere-gke, 4m41s elapsed]
google_container_cluster.primary: Destruction complete after 4m49s
google_compute_subnetwork.subnet: Destroying... [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet]
google_compute_subnetwork.subnet: Still destroying... [id=projects/gks-nowhere/regions/us-east1/subnetworks/gks-nowhere-subnet, 10s elapsed]
google_compute_subnetwork.subnet: Destruction complete after 14s
google_compute_network.vpc: Destroying... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc]
google_compute_network.vpc: Still destroying... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc, 10s elapsed]
google_compute_network.vpc: Still destroying... [id=projects/gks-nowhere/global/networks/gks-nowhere-vpc, 20s elapsed]
google_compute_network.vpc: Destruction complete after 22s
